data:
  organised_data_folder_path: "data/data_sources"
  shakespeare_data_source: "dataset_shakespeare_collection.json"
  impostors_data_source: "dataset_impostors.json"
  classify_text_data_source: "text_to_classify.json"
  trained_models_path: "saved_trained_models/"
  shakespeare_path: "data/raw/shakespeare"
  impostors_path: "data/raw/impostors"

training:
  optimizer:
    initial_learning_rate: 1e-4
    learning_rate_decay_factor: 0.1
    gradient_clipping_threshold: 1.0 # or 5.0
  loss: "binary_crossentropy"
  batch_factor: 8 # Chunk to Batch ratio
  chunk_size: 400 # 32 # or 64
  hidden_size: 768
  epochs: 5 # 10-20
  early_stopping_patience: 2
  impostor_chunk_ratio: 2
  test_split: 0.25

model:
  save_trained_models: True
  load_trained_models: True
  cnn:
    filters: 64 # 128 or 256
    padding: "valid"
    kernel_size: 3 # [3, 6, 12]
    pool_size: 1
  bilstm:
    dropout: 0.25 # 0.2 - 0.5
    number_of_layers: 500
  fc:
    in_features: 128
    out_features: 1

isolation_forest:
  number_of_trees: 100

bert:
  model: "bert-base-uncased"
  maximum_sequence_length: 512 # padding to that value
  trainable: True

wandb:
  enabled: True
  run_name: "full-procedure-run"
  project: "siamese-authorship-verification"
  api_key: 99cb11ef59cac847e6b99323c0d485a69157f548