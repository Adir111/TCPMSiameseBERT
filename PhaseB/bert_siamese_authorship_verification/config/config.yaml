data:
  organised_data_folder_path: "data/data_sources"
  shakespeare_data_source: "dataset_shakespeare_collection.json"
  impostors_data_source: "dataset_impostors.json"
  shakespeare_path: "data/raw/shakespeare"
  impostors_path: "data/raw/impostors"
  all_impostors_data_source: "dataset_all_impostors.json"
  classify_text_data_source: "text_to_classify.json"
  fine_tuned_bert_model_path: "saved_trained_models/berts/"
  trained_siamese_path: "saved_trained_models/models/"
  signals_folder_name: "signals_per_model"
  isolation_forest:
    isolation_forest_folder_name: "isolation_forest_per_model"
    all_models_scores_file_name: "all_models_isolation_forest_score.json"
  clustering_folder_name: "clustering"
  dtw:
    output_distance_folder: "distance_per_model"
    dtw_file_name: "distance_matrix.json"
    included_text_names_file_name: "included_text_names.json"
    signals_file_name: "processed_signals.json"
  pairs: "pairs.json"
  all_signals: "all_signals.json"

training:
  load_pretrained_model: False
  optimizer:
    initial_learning_rate: 1e-5
    learning_rate_decay_factor: 0.1
    gradient_clipping_threshold: 1.0 # or 5.0
  training_batch_size: 8
  epochs: 10
  early_stopping:
    monitor: "val_accuracy"
    patience: 4
    baseline: 0.97
  impostor_chunk_ratio: 4
  test_split: 0.25

model:
  chunk_to_batch_ratio: 8
  chunk_size: 50
  cnn:
    filters: 500
    padding: "valid"
    kernel_size: [3, 6, 12]
    pool_size: 1
  bilstm:
    dropout: 0.25 # 0.2 - 0.5
    units: 500
  fc:
    in_features: 512
    out_features: 512

isolation_forest:
  number_of_trees: 100
  percentile_threshold: 5
  anomaly_score_threshold: 0.000025

clustering:
  algorithm: "k-medoids"
  increment: 10 # Leave empty to ignore this, and just do all models at once.
  k-medoids:
    n_clusters: 2
    random_state: 0


bert:
  model: "bert-base-uncased"
  repository: "ElyMK1/bert-shakespeare-english-mlm"
  max_sequence_length: 512
  mlm_probability: 0.15
  train_batch_size: 16
  num_epochs: 5
  save_steps: 1000
  save_total_limit: 2
  logging_steps: 500
  logging_dir: "logs/shakespeare"
  token: "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"


wandb:
  enabled: False
  run_name: "full-procedure-run"
  project: "siamese-authorship-verification"
  artifact_name: "siamese-authorship-verification-branches"
  api_key: 8dc3df6ba5ef5bae0ad60917973e82163f35bdf8